{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import phonenumbers\n",
    "from phonenumbers.phonenumberutil import region_code_for_number\n",
    "import requests\n",
    "import pycountry\n",
    "from fuzzywuzzy import process\n",
    "import random\n",
    "import string\n",
    "import regex as re\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df = pd.read_excel(\"Vibely Dataset.xlsx\", sheet_name=\"Accounts\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_cleaning = accounts_df[[\"city\", \"country\", \"ip_address\", \"phone_number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_code_to_name(country_code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=country_code)\n",
    "        if country:\n",
    "            return country.name\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def ip_to_country(ip_address):\n",
    "        \n",
    "    try:\n",
    "        response = requests.get(f\"https://ipinfo.io/{ip_address}/json\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return country_code_to_name(data.get('country'))\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def city_to_country(city):\n",
    "    geolocator = Nominatim(user_agent=\"city_to_country_converter\")\n",
    "    location = geolocator.geocode(city, language=\"en\")\n",
    "    if location:\n",
    "        return location.address.split(\",\")[-1].strip()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def phone_number_to_country(phone_number):\n",
    "    try:\n",
    "        parsed_number = phonenumbers.parse(phone_number)\n",
    "        country_code = region_code_for_number(parsed_number)\n",
    "        if country_code:\n",
    "            return country_code_to_name(country_code)\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_6752\\942570911.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# Non standard country codes exist in data: remove them and then run fill script to fill them\n",
    "mask = country_cleaning[\"country\"].apply(lambda x: isinstance(x, str) and len(x.strip()) == 2)\n",
    "country_cleaning.loc[mask, \"country\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_6752\\1536486857.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"phone_number\"].apply(lambda x: phone_number_to_country(x))\n",
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_6752\\1536486857.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"city\"].apply(lambda x: city_to_country(x))\n",
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_6752\\1536486857.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"ip_address\"].apply(lambda x: ip_to_country(x))\n"
     ]
    }
   ],
   "source": [
    "# Fill missing country values using phone number\n",
    "mask = country_cleaning[\"country\"].isna() & ~country_cleaning[\"phone_number\"].isna()\n",
    "country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"phone_number\"].apply(lambda x: phone_number_to_country(x))\n",
    "\n",
    "# Fill missing values using the city\n",
    "mask = country_cleaning[\"country\"].isna() & ~country_cleaning[\"city\"].isna()\n",
    "country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"city\"].apply(lambda x: city_to_country(x))\n",
    "\n",
    "# Fill remaining missing country values using the ip address\n",
    "mask = country_cleaning[\"country\"].isna() & ~country_cleaning[\"ip_address\"].isna()\n",
    "country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"ip_address\"].apply(lambda x: ip_to_country(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_country(country_input:str):\n",
    "    countries = [\n",
    "        \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"Antigua and Barbuda\", \"Argentina\", \"Armenia\",\n",
    "        \"Australia\", \"Austria\", \"Azerbaijan\", \"Bahamas\", \"Bahrain\", \"Bangladesh\", \"Barbados\", \"Belarus\", \"Belgium\",\n",
    "        \"Belize\", \"Benin\", \"Bhutan\", \"Bolivia\", \"Bosnia and Herzegovina\", \"Botswana\", \"Brazil\", \"Brunei\", \"Bulgaria\",\n",
    "        \"Burkina Faso\", \"Burundi\", \"Cabo Verde\", \"Cambodia\", \"Cameroon\", \"Canada\", \"Central African Republic\", \"Chad\",\n",
    "        \"Chile\", \"China\", \"Colombia\", \"Comoros\", \"Congo\", \"Costa Rica\", \"Croatia\", \"Cuba\", \"Cyprus\", \"Czech Republic\",\n",
    "        \"Denmark\", \"Djibouti\", \"Dominica\", \"Dominican Republic\", \"East Timor\", \"Ecuador\", \"Egypt\", \"El Salvador\",\n",
    "        \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\", \"Ethiopia\", \"Fiji\", \"Finland\", \"France\", \"Gabon\",\n",
    "        \"Gambia\", \"Georgia\", \"Germany\", \"Ghana\", \"Greece\", \"Grenada\", \"Guatemala\", \"Guinea\", \"Guinea-Bissau\", \"Guyana\",\n",
    "        \"Haiti\", \"Honduras\", \"Hungary\", \"Iceland\", \"India\", \"Indonesia\", \"Iran\", \"Iraq\", \"Ireland\", \"Israel\", \"Italy\",\n",
    "        \"Ivory Coast\", \"Jamaica\", \"Japan\", \"Jordan\", \"Kazakhstan\", \"Kenya\", \"Kiribati\", \"Kosovo\", \"Kuwait\", \"Kyrgyzstan\",\n",
    "        \"Laos\", \"Latvia\", \"Lebanon\", \"Lesotho\", \"Liberia\", \"Libya\", \"Liechtenstein\", \"Lithuania\", \"Luxembourg\",\n",
    "        \"Madagascar\", \"Malawi\", \"Malaysia\", \"Maldives\", \"Mali\", \"Malta\", \"Marshall Islands\", \"Mauritania\", \"Mauritius\",\n",
    "        \"Mexico\", \"Micronesia\", \"Moldova\", \"Monaco\", \"Mongolia\", \"Montenegro\", \"Morocco\", \"Mozambique\", \"Myanmar\",\n",
    "        \"Namibia\", \"Nauru\", \"Nepal\", \"Netherlands\", \"New Zealand\", \"Nicaragua\", \"Niger\", \"Nigeria\", \"North Korea\",\n",
    "        \"North Macedonia\", \"Norway\", \"Oman\", \"Pakistan\", \"Palau\", \"Palestine\", \"Panama\", \"Papua New Guinea\", \"Paraguay\",\n",
    "        \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\", \"Saint Kitts and Nevis\",\n",
    "        \"Saint Lucia\", \"Saint Vincent and the Grenadines\", \"Samoa\", \"San Marino\", \"Sao Tome and Principe\", \"Saudi Arabia\",\n",
    "        \"Senegal\", \"Serbia\", \"Seychelles\", \"Sierra Leone\", \"Singapore\", \"Slovakia\", \"Slovenia\", \"Solomon Islands\",\n",
    "        \"Somalia\", \"South Africa\", \"South Korea\", \"South Sudan\", \"Spain\", \"Sri Lanka\", \"Sudan\", \"Suriname\", \"Sweden\",\n",
    "        \"Switzerland\", \"Syria\", \"Taiwan\", \"Tajikistan\", \"Tanzania\", \"Thailand\", \"Togo\", \"Tonga\", \"Trinidad and Tobago\",\n",
    "        \"Tunisia\", \"Turkey\", \"Turkmenistan\", \"Tuvalu\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\", \"United Kingdom\",\n",
    "        \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\", \"Vatican City\", \"Venezuela\", \"Vietnam\", \"Yemen\", \"Zambia\",\n",
    "        \"Zimbabwe\"\n",
    "    ]\n",
    "\n",
    "    if isinstance(country_input, str) and country_input:\n",
    "        return process.extractOne(country_input, countries)[0]\n",
    "    else:\n",
    "        return \"Prefer not to say\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting inconsistent country inputs using fuzzy matching\n",
    "mask = ~country_cleaning[\"country\"].isna()\n",
    "accounts_df.loc[mask, \"country\"] = country_cleaning.loc[mask, \"country\"].apply(lambda x: consistent_country(x))\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_gender(gender_input:str):\n",
    "    valid_set = [\"Male\", \"Female\", \"Gender Fluid\", \"Non Binary\", \"Prefer not to say\"]\n",
    "\n",
    "    if isinstance(gender_input, str) and gender_input:\n",
    "        if gender_input == \"M\":\n",
    "            return \"Male\"\n",
    "        elif gender_input == \"F\":\n",
    "            return \"Female\"\n",
    "        else:\n",
    "            return process.extractOne(gender_input, valid_set)[0]\n",
    "    else:\n",
    "        return \"Prefer not to say\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df.loc[:, \"gender\"] = accounts_df.loc[:, \"gender\"].apply(lambda x: consistent_gender(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def username_from_email(email):\n",
    "    at_index = email.find(\"@\")\n",
    "    return email[:at_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = accounts_df[\"username\"].isna() & ~accounts_df[\"email\"].isna()\n",
    "accounts_df.loc[mask, \"username\"] = accounts_df.loc[mask, \"email\"].apply(lambda x: username_from_email(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_username(length=8):\n",
    "    characters = string.ascii_lowercase + string.digits\n",
    "    return ''.join(random.choice(characters) for i in range(length))\n",
    "\n",
    "existing_users = accounts_df[\"username\"].tolist()\n",
    "for index, row in accounts_df.iterrows():\n",
    "    \n",
    "    if pd.isna(row[\"username\"]):\n",
    "        random_username = generate_random_username()\n",
    "        if random_username not in existing_users:\n",
    "            accounts_df.iloc[index, 2] = random_username\n",
    "            existing_users.append(random_username)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and deduplicate users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to indicate duplicates\n",
    "accounts_df['is_duplicate'] = (~accounts_df['username'].isnull()) & accounts_df.duplicated(subset='username', keep=False)\n",
    "\n",
    "# Function to combine interests into a list\n",
    "def combine_interests(group):\n",
    "    all_interests = ','.join(group['interests']).split(',')\n",
    "    unique_interests = list(set(all_interests))\n",
    "    return pd.Series({'combined_interests': [','.join(unique_interests)]})\n",
    "\n",
    "\n",
    "# Group by 'username' and aggregate 'interests' into a list\n",
    "merged_df = accounts_df.groupby(['username', 'is_duplicate']).apply(combine_interests)\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "accounts_df.drop(columns=[\"is_duplicate\"], inplace = True)\n",
    "semi_clean_df = accounts_df.merge(merged_df[[\"combined_interests\", \"username\"]], on='username', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_clean_df = accounts_df.merge(merged_df[[\"combined_interests\", \"username\"]], on='username', how='left')\n",
    "semi_clean_df.drop_duplicates(subset=['username'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subscription(row):\n",
    "    if row in [1, \"Yes\", \"yes\", \"1\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_6752\\1136445598.py:1: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  semi_clean_df.loc[:, \"subscription\"] = semi_clean_df.loc[:, \"subscription\"].apply(lambda x: clean_subscription(x))\n"
     ]
    }
   ],
   "source": [
    "semi_clean_df.loc[:, \"subscription\"] = semi_clean_df.loc[:, \"subscription\"].apply(lambda x: clean_subscription(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit card type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_card_type(card_type:str):\n",
    "    valid_set = [\"mastercard\", \"jcb\", \"americanexpress\",\n",
    "                    \"visa\", \"maestro\", \"paypal\", \"dinersclub\",\n",
    "                    \"chinaunionpay\", \"creditcard\", \"debitcard\", \"laser\",\n",
    "                    \"bankcard\", \"instapayment\", \"solo\", \"switch\", \"card\"\n",
    "                ]\n",
    "\n",
    "    if isinstance(card_type, str) and card_type:\n",
    "        result, threshold = process.extractOne(card_type, valid_set)\n",
    "        if threshold >= 75:\n",
    "            return result\n",
    "        else:\n",
    "            return np.nan\n",
    "    else: \n",
    "        return np.nan\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '-']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '!!']\n"
     ]
    }
   ],
   "source": [
    "semi_clean_df.loc[:, \"card_type\"] = semi_clean_df.loc[:, \"card_type\"].apply(lambda x: consistent_card_type(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birth Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_fuzzy_match(month_str):\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    months_dict = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "    return months_dict[process.extractOne(month_str, months)[0]]\n",
    "\n",
    "\n",
    "def two_len_year(year):\n",
    "    if len(year) == 2 and int(year) > 23:\n",
    "        return \"19\" + year\n",
    "    elif len(year) == 2:\n",
    "        return \"20\" + year\n",
    "            \n",
    "\n",
    "def date_list_to_datetime(date):\n",
    "    a = date[0]\n",
    "    b = date[1]\n",
    "    c = date[2]\n",
    "    if len(c) == 2:\n",
    "        c = two_len_year(c)\n",
    "    try:\n",
    "        return datetime.datetime(day=int(a), month=int(b), year=int(c))\n",
    "    except:\n",
    "        return datetime.datetime(day=int(b), month=int(a), year=int(c))\n",
    "\n",
    "\n",
    "def clean_birth_date(birth_date):\n",
    "    if isinstance(birth_date, str):\n",
    "        if \"/\" in birth_date:\n",
    "            try:\n",
    "                date = birth_date.split(\"/\")\n",
    "                return date_list_to_datetime(date)\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "        elif \"-\" in birth_date:\n",
    "            try:\n",
    "                date = birth_date.split(\"-\")\n",
    "                return date_list_to_datetime(date)\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "        else:\n",
    "            matches = re.search(r\"(\\d*)?(th)? ?(\\w*) (\\d*)\", birth_date)\n",
    "            try:\n",
    "                day, _, month, year = matches.groups()\n",
    "                if len(year) == 2:\n",
    "                    year = two_len_year(year)\n",
    "\n",
    "                if not day:\n",
    "                    day = 1\n",
    "                return datetime.datetime(day=int(day), month=month_fuzzy_match(month), year=int(year))\n",
    "            except:\n",
    "                return np.nan\n",
    "    else:\n",
    "        if isinstance(birth_date, datetime.datetime):\n",
    "            return birth_date\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "def check_valid_date(date):\n",
    "    if isinstance(date, datetime.datetime):\n",
    "        if date.year > 2024 or date.year < 1900:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return date\n",
    "    else:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_6752\\79252899.py:1: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  semi_clean_df.loc[:, \"birth_date \"] = semi_clean_df.loc[:, \"birth_date \"].apply(lambda x: check_valid_date(clean_birth_date(x)))\n"
     ]
    }
   ],
   "source": [
    "semi_clean_df.loc[:, \"birth_date \"] = semi_clean_df.loc[:, \"birth_date \"].apply(lambda x: check_valid_date(clean_birth_date(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = semi_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
