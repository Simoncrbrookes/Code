{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import phonenumbers\n",
    "from phonenumbers.phonenumberutil import region_code_for_number\n",
    "import requests\n",
    "import pycountry\n",
    "from fuzzywuzzy import process\n",
    "import random\n",
    "import string\n",
    "import regex as re\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df = pd.read_excel(\"Vibely Dataset.xlsx\", sheet_name=\"Accounts\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_cleaning = accounts_df[[\"city\", \"country\", \"ip_address\", \"phone_number\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_code_to_name(country_code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=country_code)\n",
    "        if country:\n",
    "            return country.name\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def ip_to_country(ip_address):\n",
    "        \n",
    "    try:\n",
    "        response = requests.get(f\"https://ipinfo.io/{ip_address}/json\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return country_code_to_name(data.get('country'))\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def city_to_country(city):\n",
    "    geolocator = Nominatim(user_agent=\"city_to_country_converter\")\n",
    "    location = geolocator.geocode(city, language=\"en\")\n",
    "    if location:\n",
    "        return location.address.split(\",\")[-1].strip()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def phone_number_to_country(phone_number):\n",
    "    try:\n",
    "        parsed_number = phonenumbers.parse(phone_number)\n",
    "        country_code = region_code_for_number(parsed_number)\n",
    "        if country_code:\n",
    "            return country_code_to_name(country_code)\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_12972\\942570911.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# Non standard country codes exist in data: remove them and then run fill script to fill them\n",
    "mask = country_cleaning[\"country\"].apply(lambda x: isinstance(x, str) and len(x.strip()) == 2)\n",
    "country_cleaning.loc[mask, \"country\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_12972\\1536486857.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"phone_number\"].apply(lambda x: phone_number_to_country(x))\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Newport&format=json&limit=1&accept-language=en\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\")': /search?q=Verona&format=json&limit=1&accept-language=en\n",
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_12972\\1536486857.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"city\"].apply(lambda x: city_to_country(x))\n",
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_12972\\1536486857.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"ip_address\"].apply(lambda x: ip_to_country(x))\n"
     ]
    }
   ],
   "source": [
    "# Fill missing country values using phone number\n",
    "mask = country_cleaning[\"country\"].isna() & ~country_cleaning[\"phone_number\"].isna()\n",
    "country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"phone_number\"].apply(lambda x: phone_number_to_country(x))\n",
    "\n",
    "# Fill missing values using the city\n",
    "mask = country_cleaning[\"country\"].isna() & ~country_cleaning[\"city\"].isna()\n",
    "country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"city\"].apply(lambda x: city_to_country(x))\n",
    "\n",
    "# Fill remaining missing country values using the ip address\n",
    "mask = country_cleaning[\"country\"].isna() & ~country_cleaning[\"ip_address\"].isna()\n",
    "country_cleaning.loc[mask, \"country\"] = country_cleaning.loc[mask, \"ip_address\"].apply(lambda x: ip_to_country(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_country(country_input:str):\n",
    "    countries = [\n",
    "        \"Afghanistan\", \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"Antigua and Barbuda\", \"Argentina\", \"Armenia\",\n",
    "        \"Australia\", \"Austria\", \"Azerbaijan\", \"Bahamas\", \"Bahrain\", \"Bangladesh\", \"Barbados\", \"Belarus\", \"Belgium\",\n",
    "        \"Belize\", \"Benin\", \"Bhutan\", \"Bolivia\", \"Bosnia and Herzegovina\", \"Botswana\", \"Brazil\", \"Brunei\", \"Bulgaria\",\n",
    "        \"Burkina Faso\", \"Burundi\", \"Cabo Verde\", \"Cambodia\", \"Cameroon\", \"Canada\", \"Central African Republic\", \"Chad\",\n",
    "        \"Chile\", \"China\", \"Colombia\", \"Comoros\", \"Congo\", \"Costa Rica\", \"Croatia\", \"Cuba\", \"Cyprus\", \"Czech Republic\",\n",
    "        \"Denmark\", \"Djibouti\", \"Dominica\", \"Dominican Republic\", \"East Timor\", \"Ecuador\", \"Egypt\", \"El Salvador\",\n",
    "        \"Equatorial Guinea\", \"Eritrea\", \"Estonia\", \"Eswatini\", \"Ethiopia\", \"Fiji\", \"Finland\", \"France\", \"Gabon\",\n",
    "        \"Gambia\", \"Georgia\", \"Germany\", \"Ghana\", \"Greece\", \"Grenada\", \"Guatemala\", \"Guinea\", \"Guinea-Bissau\", \"Guyana\",\n",
    "        \"Haiti\", \"Honduras\", \"Hungary\", \"Iceland\", \"India\", \"Indonesia\", \"Iran\", \"Iraq\", \"Ireland\", \"Israel\", \"Italy\",\n",
    "        \"Ivory Coast\", \"Jamaica\", \"Japan\", \"Jordan\", \"Kazakhstan\", \"Kenya\", \"Kiribati\", \"Kosovo\", \"Kuwait\", \"Kyrgyzstan\",\n",
    "        \"Laos\", \"Latvia\", \"Lebanon\", \"Lesotho\", \"Liberia\", \"Libya\", \"Liechtenstein\", \"Lithuania\", \"Luxembourg\",\n",
    "        \"Madagascar\", \"Malawi\", \"Malaysia\", \"Maldives\", \"Mali\", \"Malta\", \"Marshall Islands\", \"Mauritania\", \"Mauritius\",\n",
    "        \"Mexico\", \"Micronesia\", \"Moldova\", \"Monaco\", \"Mongolia\", \"Montenegro\", \"Morocco\", \"Mozambique\", \"Myanmar\",\n",
    "        \"Namibia\", \"Nauru\", \"Nepal\", \"Netherlands\", \"New Zealand\", \"Nicaragua\", \"Niger\", \"Nigeria\", \"North Korea\",\n",
    "        \"North Macedonia\", \"Norway\", \"Oman\", \"Pakistan\", \"Palau\", \"Palestine\", \"Panama\", \"Papua New Guinea\", \"Paraguay\",\n",
    "        \"Peru\", \"Philippines\", \"Poland\", \"Portugal\", \"Qatar\", \"Romania\", \"Russia\", \"Rwanda\", \"Saint Kitts and Nevis\",\n",
    "        \"Saint Lucia\", \"Saint Vincent and the Grenadines\", \"Samoa\", \"San Marino\", \"Sao Tome and Principe\", \"Saudi Arabia\",\n",
    "        \"Senegal\", \"Serbia\", \"Seychelles\", \"Sierra Leone\", \"Singapore\", \"Slovakia\", \"Slovenia\", \"Solomon Islands\",\n",
    "        \"Somalia\", \"South Africa\", \"South Korea\", \"South Sudan\", \"Spain\", \"Sri Lanka\", \"Sudan\", \"Suriname\", \"Sweden\",\n",
    "        \"Switzerland\", \"Syria\", \"Taiwan\", \"Tajikistan\", \"Tanzania\", \"Thailand\", \"Togo\", \"Tonga\", \"Trinidad and Tobago\",\n",
    "        \"Tunisia\", \"Turkey\", \"Turkmenistan\", \"Tuvalu\", \"Uganda\", \"Ukraine\", \"United Arab Emirates\", \"United Kingdom\",\n",
    "        \"United States\", \"Uruguay\", \"Uzbekistan\", \"Vanuatu\", \"Vatican City\", \"Venezuela\", \"Vietnam\", \"Yemen\", \"Zambia\",\n",
    "        \"Zimbabwe\"\n",
    "    ]\n",
    "\n",
    "    if isinstance(country_input, str) and country_input:\n",
    "        return process.extractOne(country_input, countries)[0]\n",
    "    else:\n",
    "        return \"Prefer not to say\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting inconsistent country inputs using fuzzy matching\n",
    "mask = ~country_cleaning[\"country\"].isna()\n",
    "accounts_df.loc[mask, \"country\"] = country_cleaning.loc[mask, \"country\"].apply(lambda x: consistent_country(x))\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistent gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_gender(gender_input:str):\n",
    "    valid_set = [\"Male\", \"Female\", \"Gender Fluid\", \"Non Binary\", \"Prefer not to say\"]\n",
    "\n",
    "    if isinstance(gender_input, str) and gender_input:\n",
    "        if gender_input == \"M\":\n",
    "            return \"Male\"\n",
    "        elif gender_input == \"F\":\n",
    "            return \"Female\"\n",
    "        else:\n",
    "            return process.extractOne(gender_input, valid_set)[0]\n",
    "    else:\n",
    "        return \"Prefer not to say\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_df.loc[:, \"gender\"] = accounts_df.loc[:, \"gender\"].apply(lambda x: consistent_gender(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def username_from_email(email):\n",
    "    at_index = email.find(\"@\")\n",
    "    return email[:at_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = accounts_df[\"username\"].isna() & ~accounts_df[\"email\"].isna()\n",
    "accounts_df.loc[mask, \"username\"] = accounts_df.loc[mask, \"email\"].apply(lambda x: username_from_email(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_username(length=8):\n",
    "    characters = string.ascii_lowercase + string.digits\n",
    "    return ''.join(random.choice(characters) for i in range(length))\n",
    "\n",
    "existing_users = accounts_df[\"username\"].tolist()\n",
    "for index, row in accounts_df.iterrows():\n",
    "    \n",
    "    if pd.isna(row[\"username\"]):\n",
    "        random_username = generate_random_username()\n",
    "        if random_username not in existing_users:\n",
    "            accounts_df.iloc[index, 2] = random_username\n",
    "            existing_users.append(random_username)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge and deduplicate users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to indicate duplicates\n",
    "accounts_df['is_duplicate'] = (~accounts_df['username'].isnull()) & accounts_df.duplicated(subset='username', keep=False)\n",
    "\n",
    "# Function to combine interests into a list\n",
    "def combine_interests(group):\n",
    "    all_interests = ','.join(group['interests']).split(',')\n",
    "    unique_interests = list(set(all_interests))\n",
    "    return pd.Series({'combined_interests': [','.join(unique_interests)]})\n",
    "\n",
    "\n",
    "# Group by 'username' and aggregate 'interests' into a list\n",
    "merged_df = accounts_df.groupby(['username', 'is_duplicate']).apply(combine_interests)\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "accounts_df.drop(columns=[\"is_duplicate\"], inplace = True)\n",
    "semi_clean_df = accounts_df.merge(merged_df[[\"combined_interests\", \"username\"]], on='username', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_clean_df = accounts_df.merge(merged_df[[\"combined_interests\", \"username\"]], on='username', how='left')\n",
    "semi_clean_df.drop_duplicates(subset=['username'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>interests</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>last_name</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>password</th>\n",
       "      <th>birth_date2</th>\n",
       "      <th>card_number</th>\n",
       "      <th>job_title</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>subscription</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>card_type</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>profile_picture_URL</th>\n",
       "      <th>combined_interests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hirsch</td>\n",
       "      <td>Environment, Philosophy, Culture</td>\n",
       "      <td>hbodley0</td>\n",
       "      <td>hbodley0@slashdot.org</td>\n",
       "      <td>Bodley</td>\n",
       "      <td>Bosilovo</td>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>Male</td>\n",
       "      <td>nW0UuPAl</td>\n",
       "      <td>Rev</td>\n",
       "      <td>3.573452e+15</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>74.141.159.245</td>\n",
       "      <td>1950-02-07 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>jcb</td>\n",
       "      <td>+389 750 613 8778</td>\n",
       "      <td>http://dummyimage.com/133x100.png/5fa2dd/ffffff</td>\n",
       "      <td>[ Philosophy,Environment, Culture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gerri</td>\n",
       "      <td>Technology, Relationships</td>\n",
       "      <td>gpetricek1</td>\n",
       "      <td>gpetricek1@deliciousdays.com</td>\n",
       "      <td>Petricek</td>\n",
       "      <td>Aizkraukle</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>Female</td>\n",
       "      <td>RQhxIkB0PyV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.565316e+15</td>\n",
       "      <td>Chemical Engineer</td>\n",
       "      <td>231.171.32.149</td>\n",
       "      <td>1984-04-18 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>jcb</td>\n",
       "      <td>+371 110 603 6635</td>\n",
       "      <td>http://dummyimage.com/188x100.png/dddddd/000000</td>\n",
       "      <td>[ Relationships,Technology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lance</td>\n",
       "      <td>Technology, Philosophy, Transportation</td>\n",
       "      <td>llebel2</td>\n",
       "      <td>liiannone2@rediff.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Czarna</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Male</td>\n",
       "      <td>XserTbnunEH</td>\n",
       "      <td>Dr</td>\n",
       "      <td>3.746221e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253.106.140.96</td>\n",
       "      <td>1982-07-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-11</td>\n",
       "      <td>americanexpress</td>\n",
       "      <td>+48 549 133 0446</td>\n",
       "      <td>http://dummyimage.com/109x100.png/dddddd/000000</td>\n",
       "      <td>[ Philosophy, Transportation,Technology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Townie</td>\n",
       "      <td>Education, Healthcare, Gaming</td>\n",
       "      <td>tbloan3</td>\n",
       "      <td>tbloan3@taobao.com</td>\n",
       "      <td>Bloan</td>\n",
       "      <td>Landim</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Non Binary</td>\n",
       "      <td>DzdJYy</td>\n",
       "      <td>Rev</td>\n",
       "      <td>3.552007e+15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.80.236.185</td>\n",
       "      <td>1947-11-09 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>jcb</td>\n",
       "      <td>+351 500 434 4711</td>\n",
       "      <td>http://dummyimage.com/101x100.png/dddddd/000000</td>\n",
       "      <td>[ Healthcare, Gaming,Education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chrissy</td>\n",
       "      <td>Technology, Environment, Philosophy</td>\n",
       "      <td>clyenyng4</td>\n",
       "      <td>clyenyng4@baidu.com</td>\n",
       "      <td>Lyenyng</td>\n",
       "      <td>Hrib-Loški Potok</td>\n",
       "      <td>Slovenia</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gh64XZ</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>3.030084e+13</td>\n",
       "      <td>Biostatistician IV</td>\n",
       "      <td>23.181.127.21</td>\n",
       "      <td>2004-02-09 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>diners-club</td>\n",
       "      <td>+386 637 266 3033</td>\n",
       "      <td>http://dummyimage.com/189x100.png/5fa2dd/ffffff</td>\n",
       "      <td>[ Philosophy, Environment,Technology]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name                               interests    username  \\\n",
       "0     Hirsch        Environment, Philosophy, Culture    hbodley0   \n",
       "1      Gerri               Technology, Relationships  gpetricek1   \n",
       "2      Lance  Technology, Philosophy, Transportation     llebel2   \n",
       "3     Townie           Education, Healthcare, Gaming     tbloan3   \n",
       "4    Chrissy     Technology, Environment, Philosophy   clyenyng4   \n",
       "\n",
       "                          email last_name              city          country  \\\n",
       "0         hbodley0@slashdot.org    Bodley          Bosilovo  North Macedonia   \n",
       "1  gpetricek1@deliciousdays.com  Petricek        Aizkraukle           Latvia   \n",
       "2         liiannone2@rediff.com       NaN            Czarna           Poland   \n",
       "3            tbloan3@taobao.com     Bloan            Landim         Portugal   \n",
       "4           clyenyng4@baidu.com   Lyenyng  Hrib-Loški Potok         Slovenia   \n",
       "\n",
       "       gender     password birth_date2   card_number           job_title  \\\n",
       "0        Male     nW0UuPAl         Rev  3.573452e+15    Internal Auditor   \n",
       "1      Female  RQhxIkB0PyV         NaN  3.565316e+15   Chemical Engineer   \n",
       "2        Male  XserTbnunEH          Dr  3.746221e+14                 NaN   \n",
       "3  Non Binary       DzdJYy         Rev  3.552007e+15                 NaN   \n",
       "4      Female       Gh64XZ         Mrs  3.030084e+13  Biostatistician IV   \n",
       "\n",
       "       ip_address          birth_date  subscription account_creation_date  \\\n",
       "0  74.141.159.245  1950-02-07 00:00:00            0            2021-06-08   \n",
       "1  231.171.32.149  1984-04-18 00:00:00            0            2021-06-11   \n",
       "2  253.106.140.96  1982-07-14 00:00:00            0            2020-10-11   \n",
       "3  124.80.236.185  1947-11-09 00:00:00            1            2019-12-27   \n",
       "4   23.181.127.21  2004-02-09 00:00:00            0            2018-12-05   \n",
       "\n",
       "         card_type       phone_number  \\\n",
       "0              jcb  +389 750 613 8778   \n",
       "1              jcb  +371 110 603 6635   \n",
       "2  americanexpress   +48 549 133 0446   \n",
       "3              jcb  +351 500 434 4711   \n",
       "4      diners-club  +386 637 266 3033   \n",
       "\n",
       "                               profile_picture_URL  \\\n",
       "0  http://dummyimage.com/133x100.png/5fa2dd/ffffff   \n",
       "1  http://dummyimage.com/188x100.png/dddddd/000000   \n",
       "2  http://dummyimage.com/109x100.png/dddddd/000000   \n",
       "3  http://dummyimage.com/101x100.png/dddddd/000000   \n",
       "4  http://dummyimage.com/189x100.png/5fa2dd/ffffff   \n",
       "\n",
       "                         combined_interests  \n",
       "0        [ Philosophy,Environment, Culture]  \n",
       "1               [ Relationships,Technology]  \n",
       "2  [ Philosophy, Transportation,Technology]  \n",
       "3           [ Healthcare, Gaming,Education]  \n",
       "4     [ Philosophy, Environment,Technology]  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue with semi_clean_df\n",
    "semi_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 'No', 'Yes', datetime.datetime(2006, 12, 26, 0, 0), 'O',\n",
       "       datetime.datetime(1981, 6, 14, 0, 0), 'yes', 'no',\n",
       "       datetime.datetime(1964, 6, 27, 0, 0),\n",
       "       datetime.datetime(1962, 10, 17, 0, 0), 'Next month',\n",
       "       datetime.datetime(1989, 4, 29, 0, 0),\n",
       "       datetime.datetime(1992, 6, 10, 0, 0), nan, 'Not sure', 'o', 3],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_clean_df[\"subscription\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_subscription(row):\n",
    "    if row in [1, \"Yes\", \"yes\", \"1\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DomMaciulaitis\\AppData\\Local\\Temp\\ipykernel_12972\\1136445598.py:1: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  semi_clean_df.loc[:, \"subscription\"] = semi_clean_df.loc[:, \"subscription\"].apply(lambda x: clean_subscription(x))\n"
     ]
    }
   ],
   "source": [
    "semi_clean_df.loc[:, \"subscription\"] = semi_clean_df.loc[:, \"subscription\"].apply(lambda x: clean_subscription(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit card type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>interests</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>last_name</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>password</th>\n",
       "      <th>birth_date2</th>\n",
       "      <th>card_number</th>\n",
       "      <th>job_title</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>subscription</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>card_type</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>profile_picture_URL</th>\n",
       "      <th>combined_interests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hirsch</td>\n",
       "      <td>Environment, Philosophy, Culture</td>\n",
       "      <td>hbodley0</td>\n",
       "      <td>hbodley0@slashdot.org</td>\n",
       "      <td>Bodley</td>\n",
       "      <td>Bosilovo</td>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>Male</td>\n",
       "      <td>nW0UuPAl</td>\n",
       "      <td>Rev</td>\n",
       "      <td>3.573452e+15</td>\n",
       "      <td>Internal Auditor</td>\n",
       "      <td>74.141.159.245</td>\n",
       "      <td>1950-02-07 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>jcb</td>\n",
       "      <td>+389 750 613 8778</td>\n",
       "      <td>http://dummyimage.com/133x100.png/5fa2dd/ffffff</td>\n",
       "      <td>[ Culture,Environment, Philosophy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name                         interests  username  \\\n",
       "0     Hirsch  Environment, Philosophy, Culture  hbodley0   \n",
       "\n",
       "                   email last_name      city          country gender  \\\n",
       "0  hbodley0@slashdot.org    Bodley  Bosilovo  North Macedonia   Male   \n",
       "\n",
       "   password birth_date2   card_number         job_title      ip_address  \\\n",
       "0  nW0UuPAl         Rev  3.573452e+15  Internal Auditor  74.141.159.245   \n",
       "\n",
       "           birth_date   subscription account_creation_date card_type  \\\n",
       "0  1950-02-07 00:00:00             0            2021-06-08       jcb   \n",
       "\n",
       "        phone_number                              profile_picture_URL  \\\n",
       "0  +389 750 613 8778  http://dummyimage.com/133x100.png/5fa2dd/ffffff   \n",
       "\n",
       "                   combined_interests  \n",
       "0  [ Culture,Environment, Philosophy]  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_clean_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jcb', 'americanexpress', 'diners-club', 'visa', 'bankcard',\n",
       "       'debit', 'solo', 'maestro', 'laser', 'switch', 'mastercard',\n",
       "       'instapayment', 'china-unionpay', 'debit ', 'v1sa', 'credit card ',\n",
       "       'credit', 'debit-card', 'card', 'instapaym3nt', 'maestrocard ',\n",
       "       'none', '-', 'bankc@rd', '!!', 'sw!tch', 'maestrocard',\n",
       "       'credit-card', 'test', 's0lo', 'X', 'paypal', nan, 'd!ners-club',\n",
       "       'Credit-Card'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_clean_df[\"card_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistent_card_type(card_type:str):\n",
    "    valid_set = [\"mastercard\", \"jcb\", \"americanexpress\",\n",
    "                    \"visa\", \"maestro\", \"paypal\", \"dinersclub\",\n",
    "                    \"chinaunionpay\", \"creditcard\", \"debitcard\", \"laser\",\n",
    "                    \"bankcard\", \"instapayment\", \"solo\", \"switch\", \"card\"\n",
    "                ]\n",
    "\n",
    "    if isinstance(card_type, str) and card_type:\n",
    "        result, threshold = process.extractOne(card_type, valid_set)\n",
    "        if threshold >= 75:\n",
    "            return result\n",
    "        else:\n",
    "            return np.nan\n",
    "    else: \n",
    "        return np.nan\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_clean_df.loc[:, \"card_type\"] = semi_clean_df.loc[:, \"card_type\"].apply(lambda x: consistent_card_type(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birth Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1950-02-07 00:00:00\n",
       "1        1984-04-18 00:00:00\n",
       "2        1982-07-14 00:00:00\n",
       "3        1947-11-09 00:00:00\n",
       "4        2004-02-09 00:00:00\n",
       "                ...         \n",
       "11005    2007-11-08 00:00:00\n",
       "11006                    NaN\n",
       "11007    1964-06-05 00:00:00\n",
       "11008                    NaN\n",
       "11009                    NaN\n",
       "Name: birth_date , Length: 11004, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_clean_df[\"birth_date \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_fuzzy_match(month_str):\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    months_dict = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "    return months_dict[process.extractOne(month_str, months)[0]]\n",
    "\n",
    "\n",
    "def two_len_year(year):\n",
    "    if len(year) == 2 and int(year) > 23:\n",
    "        return \"19\" + year\n",
    "    elif len(year) == 2:\n",
    "        return \"20\" + year\n",
    "            \n",
    "\n",
    "def date_list_to_datetime(date):\n",
    "    a = date[0]\n",
    "    b = date[1]\n",
    "    c = date[2]\n",
    "    if len(c) == 2:\n",
    "        c = two_len_year(c)\n",
    "    try:\n",
    "        return datetime.datetime(day=int(a), month=int(b), year=int(c))\n",
    "    except:\n",
    "        return datetime.datetime(day=int(b), month=int(a), year=int(c))\n",
    "\n",
    "\n",
    "def clean_birth_date(birth_date):\n",
    "    if isinstance(birth_date, str):\n",
    "        if \"/\" in birth_date:\n",
    "            try:\n",
    "                date = birth_date.split(\"/\")\n",
    "                return date_list_to_datetime(date)\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "        elif \"-\" in birth_date:\n",
    "            try:\n",
    "                date = birth_date.split(\"-\")\n",
    "                return date_list_to_datetime(date)\n",
    "            except:\n",
    "                return np.nan\n",
    "            \n",
    "        else:\n",
    "            matches = re.search(r\"(\\d*)?(th)? ?(\\w*) (\\d*)\", birth_date)\n",
    "            try:\n",
    "                day, _, month, year = matches.groups()\n",
    "                if len(year) == 2:\n",
    "                    year = two_len_year(year)\n",
    "\n",
    "                if not day:\n",
    "                    day = 1\n",
    "                return datetime.datetime(day=int(day), month=month_fuzzy_match(month), year=int(year))\n",
    "            except:\n",
    "                return np.nan\n",
    "    else:\n",
    "        if isinstance(birth_date, datetime.datetime):\n",
    "            return birth_date\n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    }
   ],
   "source": [
    "semi_clean_df.loc[:, \"birth_date \"] = semi_clean_df.loc[:, \"birth_date \"].apply(lambda x: clean_birth_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = semi_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(final_df[\"birth_date \"], datetime.datetime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
